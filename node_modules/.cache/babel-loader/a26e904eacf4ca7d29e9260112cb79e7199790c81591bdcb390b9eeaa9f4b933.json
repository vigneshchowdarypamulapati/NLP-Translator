{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\VIGGU\\\\codes\\\\REACT JS\\\\NLPTranslator\\\\src\\\\components\\\\Livetrans.js\",\n  _s = $RefreshSig$();\nimport React from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport default function Livetrans() {\n  _s();\n  const startListening = () => SpeechRecognition.startListening({\n    continuous: true,\n    language: \"en-IN\"\n  });\n  const {\n    transcript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n  if (!browserSupportsSpeechRecognition) {\n    return null;\n  }\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"container\",\n      style: {\n        width: \"100%\",\n        height: \"100%\",\n        display: \"flex\"\n      },\n      children: /*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Speech to Text Converter\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 23,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 18,\n      columnNumber: 7\n    }, this)\n  }, void 0, false);\n}\n_s(Livetrans, \"HIOsR6Ydovy/i3vOlFRHflRzTwU=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = Livetrans;\nvar _c;\n$RefreshReg$(_c, \"Livetrans\");","map":{"version":3,"names":["React","SpeechRecognition","useSpeechRecognition","jsxDEV","_jsxDEV","Fragment","_Fragment","Livetrans","_s","startListening","continuous","language","transcript","browserSupportsSpeechRecognition","children","className","style","width","height","display","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/VIGGU/codes/REACT JS/NLPTranslator/src/components/Livetrans.js"],"sourcesContent":["import React from \"react\";\r\nimport SpeechRecognition, {\r\n  useSpeechRecognition,\r\n} from \"react-speech-recognition\";\r\n\r\nexport default function Livetrans() {\r\n  const startListening = () =>\r\n    SpeechRecognition.startListening({ continuous: true, language: \"en-IN\" });\r\n  const { transcript, browserSupportsSpeechRecognition } =\r\n    useSpeechRecognition();\r\n\r\n  if (!browserSupportsSpeechRecognition) {\r\n    return null;\r\n  }\r\n\r\n  return (\r\n    <>\r\n      <div className=\"container\" style={{\r\n          width: \"100%\",\r\n          height: \"100%\",\r\n          display: \"flex\",\r\n        }}>\r\n        <h2>Speech to Text Converter</h2>\r\n        {/* <p>\r\n          A React hook that converts speech from the microphone to text and\r\n          makes it available to your React components.\r\n        </p> */}\r\n      </div>\r\n      \r\n    </>\r\n  );\r\n}\r\n"],"mappings":";;AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,iBAAiB,IACtBC,oBAAoB,QACf,0BAA0B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAAA,SAAAC,QAAA,IAAAC,SAAA;AAElC,eAAe,SAASC,SAASA,CAAA,EAAG;EAAAC,EAAA;EAClC,MAAMC,cAAc,GAAGA,CAAA,KACrBR,iBAAiB,CAACQ,cAAc,CAAC;IAAEC,UAAU,EAAE,IAAI;IAAEC,QAAQ,EAAE;EAAQ,CAAC,CAAC;EAC3E,MAAM;IAAEC,UAAU;IAAEC;EAAiC,CAAC,GACpDX,oBAAoB,EAAE;EAExB,IAAI,CAACW,gCAAgC,EAAE;IACrC,OAAO,IAAI;EACb;EAEA,oBACET,OAAA,CAAAE,SAAA;IAAAQ,QAAA,eACEV,OAAA;MAAKW,SAAS,EAAC,WAAW;MAACC,KAAK,EAAE;QAC9BC,KAAK,EAAE,MAAM;QACbC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;MACX,CAAE;MAAAL,QAAA,eACFV,OAAA;QAAAU,QAAA,EAAI;MAAwB;QAAAM,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA;IAAK;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAK7B,iBAEL;AAEP;AAACf,EAAA,CA1BuBD,SAAS;EAAA,QAI7BL,oBAAoB;AAAA;AAAAsB,EAAA,GAJAjB,SAAS;AAAA,IAAAiB,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}
{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\VIGGU\\\\codes\\\\REACT JS\\\\NLPTranslator\\\\src\\\\components\\\\Livetrans.js\",\n  _s = $RefreshSig$();\nimport \"../App.css\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport default function Livetrans() {\n  _s();\n  const startListening = () => SpeechRecognition.startListening({\n    continuous: true,\n    language: 'en-IN'\n  });\n  const {\n    transcript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n  if (!browserSupportsSpeechRecognition) {\n    return null;\n  }\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"fle\",\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Speech to Text Converter\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 16,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 17,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"A React hook that converts speech from the microphone to text and makes it available to your React components.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 18,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"main-content\",\n        children: transcript\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 21,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"btn-style\",\n        children: [/*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: startListening,\n          children: \"Start Listening\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 26,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: SpeechRecognition.stopListening,\n          children: \"Stop Listening\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 27,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 25,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 15,\n      columnNumber: 13\n    }, this)\n  }, void 0, false);\n}\n_s(Livetrans, \"HIOsR6Ydovy/i3vOlFRHflRzTwU=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = Livetrans;\n;\nvar _c;\n$RefreshReg$(_c, \"Livetrans\");","map":{"version":3,"names":["SpeechRecognition","useSpeechRecognition","jsxDEV","_jsxDEV","Fragment","_Fragment","Livetrans","_s","startListening","continuous","language","transcript","browserSupportsSpeechRecognition","children","className","fileName","_jsxFileName","lineNumber","columnNumber","onClick","stopListening","_c","$RefreshReg$"],"sources":["C:/Users/VIGGU/codes/REACT JS/NLPTranslator/src/components/Livetrans.js"],"sourcesContent":["import \"../App.css\"\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\n\r\nexport default function Livetrans() {\r\n    const startListening = () => SpeechRecognition.startListening({ continuous: true, language: 'en-IN' });\r\n    const { transcript, browserSupportsSpeechRecognition } = useSpeechRecognition();\r\n\r\n    if (!browserSupportsSpeechRecognition) {\r\n        return null\r\n    }\r\n\r\n    return (\r\n        <>\r\n            <div className=\"fle\">\r\n                <h2>Speech to Text Converter</h2>\r\n                <br/>\r\n                <p>A React hook that converts speech from the microphone to text and makes it available to your React\r\n                    components.</p>\r\n\r\n                <div className=\"main-content\">\r\n                    {transcript}\r\n                </div>\r\n\r\n                <div className=\"btn-style\">\r\n                    <button onClick={startListening}>Start Listening</button>\r\n                    <button onClick={SpeechRecognition.stopListening}>Stop Listening</button>\r\n\r\n                </div>\r\n\r\n            </div>\r\n\r\n        </>\r\n    );\r\n};\r\n"],"mappings":";;AAAA,OAAO,YAAY;AACnB,OAAOA,iBAAiB,IAAIC,oBAAoB,QAAQ,0BAA0B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAAA,SAAAC,QAAA,IAAAC,SAAA;AAGnF,eAAe,SAASC,SAASA,CAAA,EAAG;EAAAC,EAAA;EAChC,MAAMC,cAAc,GAAGA,CAAA,KAAMR,iBAAiB,CAACQ,cAAc,CAAC;IAAEC,UAAU,EAAE,IAAI;IAAEC,QAAQ,EAAE;EAAQ,CAAC,CAAC;EACtG,MAAM;IAAEC,UAAU;IAAEC;EAAiC,CAAC,GAAGX,oBAAoB,EAAE;EAE/E,IAAI,CAACW,gCAAgC,EAAE;IACnC,OAAO,IAAI;EACf;EAEA,oBACIT,OAAA,CAAAE,SAAA;IAAAQ,QAAA,eACIV,OAAA;MAAKW,SAAS,EAAC,KAAK;MAAAD,QAAA,gBAChBV,OAAA;QAAAU,QAAA,EAAI;MAAwB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAK,eACjCf,OAAA;QAAAY,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAK,eACLf,OAAA;QAAAU,QAAA,EAAG;MACY;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAI,eAEnBf,OAAA;QAAKW,SAAS,EAAC,cAAc;QAAAD,QAAA,EACxBF;MAAU;QAAAI,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QACT,eAENf,OAAA;QAAKW,SAAS,EAAC,WAAW;QAAAD,QAAA,gBACtBV,OAAA;UAAQgB,OAAO,EAAEX,cAAe;UAAAK,QAAA,EAAC;QAAe;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,QAAS,eACzDf,OAAA;UAAQgB,OAAO,EAAEnB,iBAAiB,CAACoB,aAAc;UAAAP,QAAA,EAAC;QAAc;UAAAE,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,QAAS;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAEvE;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAEJ,iBAEP;AAEX;AAACX,EAAA,CA9BuBD,SAAS;EAAA,QAE4BL,oBAAoB;AAAA;AAAAoB,EAAA,GAFzDf,SAAS;AA8BhC;AAAC,IAAAe,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}